{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "#import pyTruthTable as ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USER INPUT\n",
    "cnx = sqlite3.connect('data/db/homeassistant.db') #ADD LINK TO HASS DATABASE\n",
    "startDate =  pd.to_datetime('2023-5-15 00:00:00') #ADD STARTDATE FROM WHERE TO BEGIN WEEK\n",
    "interval = 20 #INTERVAL IN SECONDS OF TIMESLOTS AND SESSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql_query(\"SELECT states.state_id, states_meta.entity_id, state, DATETIME(last_updated_ts, 'unixepoch', 'localtime') as last_updated, DATETIME(IIF(states.last_changed_ts IS NULL,states.last_updated_ts,states.last_changed_ts), 'unixepoch', 'localtime') as last_changed FROM states LEFT JOIN states_meta ON (states.metadata_id=states_meta.metadata_id) LEFT JOIN state_attributes ON (states.attributes_id=state_attributes.attributes_id) WHERE last_changed_ts IS NULL;\", cnx)\n",
    "cnx.close()\n",
    "data['last_changed'] = pd.to_datetime(data['last_changed'])\n",
    "data['last_changed'] = pd.to_datetime(data['last_updated'])\n",
    "endDate = startDate + datetime.timedelta(days=14)\n",
    "data = data.loc[(data['last_changed'] >= startDate)\n",
    "                     & (data['last_changed'] <= endDate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>state</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>last_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147839</th>\n",
       "      <td>1884904</td>\n",
       "      <td>sensor.energy_price_checker_current_electricity_market_price</td>\n",
       "      <td>0.31634</td>\n",
       "      <td>2023-05-15 00:00:00</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147840</th>\n",
       "      <td>1884905</td>\n",
       "      <td>sensor.energy_price_checker_next_hour_electricity_market_price</td>\n",
       "      <td>0.30255</td>\n",
       "      <td>2023-05-15 00:00:00</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147841</th>\n",
       "      <td>1884906</td>\n",
       "      <td>sensor.energy_price_checker_lowest_energy_price_today</td>\n",
       "      <td>0.28066</td>\n",
       "      <td>2023-05-15 00:00:00</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147842</th>\n",
       "      <td>1884907</td>\n",
       "      <td>sensor.energy_price_checker_highest_energy_price_today</td>\n",
       "      <td>0.34745</td>\n",
       "      <td>2023-05-15 00:00:00</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147843</th>\n",
       "      <td>1884908</td>\n",
       "      <td>sensor.energy_price_checker_average_electricity_price_today</td>\n",
       "      <td>0.30331</td>\n",
       "      <td>2023-05-15 00:00:00</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660030</th>\n",
       "      <td>2438651</td>\n",
       "      <td>sensor.energy_price_checker_highest_energy_price_today</td>\n",
       "      <td>0.27815</td>\n",
       "      <td>2023-05-29 00:00:00</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660031</th>\n",
       "      <td>2438652</td>\n",
       "      <td>sensor.energy_price_checker_average_electricity_price_today</td>\n",
       "      <td>0.18828</td>\n",
       "      <td>2023-05-29 00:00:00</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660032</th>\n",
       "      <td>2438653</td>\n",
       "      <td>sensor.energy_price_checker_time_of_lowest_price_today</td>\n",
       "      <td>2023-05-29T12:00:00+00:00</td>\n",
       "      <td>2023-05-29 00:00:00</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660033</th>\n",
       "      <td>2438654</td>\n",
       "      <td>sensor.energy_price_checker_current_percentage_of_highest_electricity_price_today</td>\n",
       "      <td>88.5</td>\n",
       "      <td>2023-05-29 00:00:00</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660034</th>\n",
       "      <td>2438655</td>\n",
       "      <td>sensor.energy_price_checker_time_of_highest_price_today</td>\n",
       "      <td>2023-05-29T19:00:00+00:00</td>\n",
       "      <td>2023-05-29 00:00:00</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_id  \\\n",
       "147839   1884904   \n",
       "147840   1884905   \n",
       "147841   1884906   \n",
       "147842   1884907   \n",
       "147843   1884908   \n",
       "...          ...   \n",
       "660030   2438651   \n",
       "660031   2438652   \n",
       "660032   2438653   \n",
       "660033   2438654   \n",
       "660034   2438655   \n",
       "\n",
       "                                                                                entity_id  \\\n",
       "147839                       sensor.energy_price_checker_current_electricity_market_price   \n",
       "147840                     sensor.energy_price_checker_next_hour_electricity_market_price   \n",
       "147841                              sensor.energy_price_checker_lowest_energy_price_today   \n",
       "147842                             sensor.energy_price_checker_highest_energy_price_today   \n",
       "147843                        sensor.energy_price_checker_average_electricity_price_today   \n",
       "...                                                                                   ...   \n",
       "660030                             sensor.energy_price_checker_highest_energy_price_today   \n",
       "660031                        sensor.energy_price_checker_average_electricity_price_today   \n",
       "660032                             sensor.energy_price_checker_time_of_lowest_price_today   \n",
       "660033  sensor.energy_price_checker_current_percentage_of_highest_electricity_price_today   \n",
       "660034                            sensor.energy_price_checker_time_of_highest_price_today   \n",
       "\n",
       "                            state         last_updated last_changed  \n",
       "147839                    0.31634  2023-05-15 00:00:00   2023-05-15  \n",
       "147840                    0.30255  2023-05-15 00:00:00   2023-05-15  \n",
       "147841                    0.28066  2023-05-15 00:00:00   2023-05-15  \n",
       "147842                    0.34745  2023-05-15 00:00:00   2023-05-15  \n",
       "147843                    0.30331  2023-05-15 00:00:00   2023-05-15  \n",
       "...                           ...                  ...          ...  \n",
       "660030                    0.27815  2023-05-29 00:00:00   2023-05-29  \n",
       "660031                    0.18828  2023-05-29 00:00:00   2023-05-29  \n",
       "660032  2023-05-29T12:00:00+00:00  2023-05-29 00:00:00   2023-05-29  \n",
       "660033                       88.5  2023-05-29 00:00:00   2023-05-29  \n",
       "660034  2023-05-29T19:00:00+00:00  2023-05-29 00:00:00   2023-05-29  \n",
       "\n",
       "[512196 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239798"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Define entity types to be considered in data\n",
    "#entity types including \n",
    "includeNoise = False\n",
    "entityTypes = ['binary_sensor', 'light','person', 'button', 'sun', 'lock', 'media_player', 'switch', 'alarm_control_panel', 'fan', 'sensor']\n",
    "#entityTypes = ['binary_sensor', 'light', 'sun', 'fan', 'switch']\n",
    "#Manual filter\n",
    "entityFilter = []\n",
    "if includeNoise == False:\n",
    "    for entity in data['entity_id'].unique():\n",
    "        if 'binary_sensor' in entity and 'power' in entity\\\n",
    "            or 'sensor' in entity and 'power' in entity\\\n",
    "            or 'warm_water' in entity\\\n",
    "            or 'overlay' in entity\\\n",
    "            or 'early_start' in entity\\\n",
    "            or 'open_window' in entity\\\n",
    "            or 'info' in entity\\\n",
    "            or 'failure' in entity\\\n",
    "            or 'tampering' in entity\\\n",
    "            or 'temperature' in entity\\\n",
    "            or 'time' in entity\\\n",
    "            or 'program' in entity\\\n",
    "            or 'connection' in entity\\\n",
    "            or 'link' in entity\\\n",
    "            or 'current' in entity\\\n",
    "            or 'configuration' in entity\\\n",
    "            or 'overheat' in entity\\\n",
    "            or 'focus' in entity\\\n",
    "            or 'battery' in entity\\\n",
    "            or 'microwave' in entity\\\n",
    "            or 'dishwasher' in entity\\\n",
    "            or 'tdarr' in entity\\\n",
    "            or 'remote' in entity:\n",
    "            entityFilter.append(entity)\n",
    "    entityFilter\n",
    "    data = data[~data['entity_id'].isin(entityFilter)]\n",
    "#Initialize empty list of entities\n",
    "entities = []\n",
    "#Loop over all unique entities remaining\n",
    "for entity in data['entity_id'].unique():\n",
    "    #Split device type from device name\n",
    "    split = str(entity).split('.')\n",
    "    #Grab device type and see if in list of considered types\n",
    "    if split[0] in entityTypes:\n",
    "        #When true, append device to list of entities to be used\n",
    "        entities.append(entity)\n",
    "#Create dataframe of all entities to be used\n",
    "dataEntitiesFiltered = data[data['entity_id'].isin(entities)]\n",
    "len(dataEntitiesFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumnsFiltered = dataEntitiesFiltered[['entity_id', 'state', 'last_updated', 'last_changed']]\n",
    "dataUnavailableDeleted = dataColumnsFiltered[dataColumnsFiltered['state'] != 'unavailable']\n",
    "dataNaDeleted = dataUnavailableDeleted.dropna(subset='state')\n",
    "dataUnknownDeleted = dataNaDeleted[dataNaDeleted['state'] != 'unknown']\n",
    "filteredSun = dataUnknownDeleted[dataUnknownDeleted['entity_id'].str.startswith(\"sun\")].drop_duplicates(subset=['last_changed'])\n",
    "filteredSun.dropna(subset=['last_changed'], inplace=True)\n",
    "filteredRest = dataUnknownDeleted[~dataUnknownDeleted['entity_id'].str.startswith(\"sun\")]\n",
    "dataSunFix = pd.concat([filteredSun, filteredRest ]).reindex(dataUnknownDeleted.index).dropna(subset=['entity_id'])\n",
    "dataCleaned = dataSunFix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "dataCleaned = dataCleaned[dataCleaned['last_changed'].notna()]\n",
    "dataCleaned['timestamp'] = pd.to_datetime(dataCleaned['last_changed']).dt.floor('T')\n",
    "dataCleaned['id_state'] = dataCleaned['entity_id'] + '-' + dataCleaned['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round all times to the second\n",
    "dataCleaned['last_updated'] = pd.to_datetime(dataCleaned['last_updated']).dt.floor('S')\n",
    "dataCleaned['last_changed'] = pd.to_datetime(dataCleaned['last_changed']).dt.floor('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataCleaned = dataCleaned[dataCleaned['id_state'].str.contains(\"-on\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test = train_test_split(dataCleaned, test_size=0.50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "automationEntityList = ['sun_above', 'sun_below', 'binary_sensor.walk_motion_detection-on', 'binary_sensor.living_motion_detection-on', 'binary_sensor.door_bath_motion_detection-on', 'binary_sensor.downstairs_hall_motion_detection-on',\n",
    "                        'light.walk-on','light.kitchen-on','light.spots_living-on', 'light.window_living-on', 'light.sill-on','light.mirror-on','light.spots_bath-on', 'light.downstairs-on', 'light.toilet-on',\n",
    "                        'switch.ps5-on',\n",
    "                        'media_player.tv-on', 'media_player.receiver-on', 'switch.mediabox-on'\n",
    "                        ]\n",
    "#ttg.Truths(automationEntityList).as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins created with start date 2023-05-15 00:00:00 and end date 2023-05-21 20:20:00\n"
     ]
    }
   ],
   "source": [
    "#Dynamically add start and end dates to bins based on first and last value\n",
    "startDate = df['last_changed'].head(1).item().floor('T')\n",
    "endDate = df['last_changed'].tail(1).item().floor('T')\n",
    "binLength = interval\n",
    "bins = pd.date_range(start=startDate, end=endDate, freq=f'{binLength}S')\n",
    "print(f'Bins created with start date {startDate} and end date {endDate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "statefulItemsets = pd.DataFrame(columns = df['entity_id'].unique())\n",
    "statefulItemsets['timeslot'] = bins\n",
    "statefulItemsets['dow'] = statefulItemsets.apply(lambda x: pd.Timestamp(x['timeslot']).day_name(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/f0zx4qd55tqd2tj2yx17fq9h0000gn/T/ipykernel_1509/4165454882.py:3: DtypeWarning: Columns (47,48,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  statefulItemsets = pd.read_csv('data/cache/statefulItemsets.csv', index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached data found. Using old data.\n"
     ]
    }
   ],
   "source": [
    "#Set initial to true so first rows will not check for previous value when NaN\n",
    "try:\n",
    "    statefulItemsets = pd.read_csv('data/cache/statefulItemsets.csv', index_col=0)\n",
    "except:\n",
    "    startTime = time.time()\n",
    "    counter = 1\n",
    "    for row in tqdm(range(len(statefulItemsets)), desc=\"Generating stateful dataframe\"):\n",
    "        if counter <= len(statefulItemsets):\n",
    "            timeslot = row\n",
    "            entities = df[(df.last_changed >= statefulItemsets['timeslot'][row]) & (df.last_changed < statefulItemsets['timeslot'][row] + datetime.timedelta(seconds=interval))]\n",
    "            if len(entities) > 0:\n",
    "                for col in statefulItemsets.iloc[: , :-2]:\n",
    "                    if len(entities.loc[df['entity_id'] == col]) == 1:\n",
    "                        statefulItemsets.loc[row, col] = entities.loc[df['entity_id'] == col, 'state'].iloc[0]\n",
    "                    elif len(entities.loc[df['entity_id'] == col]) > 1:\n",
    "                        statefulItemsets.loc[row, col] = entities.loc[df['entity_id'] == col, 'state'].iloc[-1]\n",
    "                    elif counter > 1:\n",
    "                        statefulItemsets.loc[row, col] = statefulItemsets.loc[row-1, col]\n",
    "\n",
    "\n",
    "            elif counter > 1:\n",
    "                for col in statefulItemsets.iloc[: , :-2]:\n",
    "                    statefulItemsets.loc[row, col] = statefulItemsets.loc[row-1, col]\n",
    "        counter += 1\n",
    "    statefulItemsets.to_csv('data/cache/statefulItemsets.csv')\n",
    "    endTime = time.time()\n",
    "    runningTime = endTime - startTime\n",
    "    print(f'Generated {len(statefulItemsets)} itemsets in {runningTime} seconds!')\n",
    "else:\n",
    "    print('Cached data found. Using old data.')\n",
    "statefulItemsets.replace(['below_horizon', 'not_home', 'locked', 'idle', 'paused', 'standby', 'off'], 0, inplace=True)\n",
    "statefulItemsets.replace(['above_horizon', 'home', 'unlocked','playing', 'on'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/f0zx4qd55tqd2tj2yx17fq9h0000gn/T/ipykernel_1509/4293351084.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  statefulItemsets[entity].iloc[0:firstDataCell] = 1\n",
      "/var/folders/5p/f0zx4qd55tqd2tj2yx17fq9h0000gn/T/ipykernel_1509/4293351084.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  statefulItemsets[entity].iloc[0:firstDataCell] = 0\n"
     ]
    }
   ],
   "source": [
    "loop = 0\n",
    "for entity in statefulItemsets.loc[:, ~statefulItemsets.columns.isin(['timeslot', 'dow'])]:\n",
    "    firstDataCell = 0\n",
    "    for cell in statefulItemsets[entity]:\n",
    "        try:\n",
    "            if math.isnan(cell):\n",
    "                firstDataCell +=1 \n",
    "            else:\n",
    "                break\n",
    "        except: continue\n",
    "    if firstDataCell > 0 and firstDataCell != len(statefulItemsets):\n",
    "        actual = statefulItemsets[entity].iloc[firstDataCell]\n",
    "        if actual == 1 or actual == 1.0:\n",
    "            statefulItemsets[entity].iloc[0:firstDataCell] = 0\n",
    "        else:\n",
    "            statefulItemsets[entity].iloc[0:firstDataCell] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted duplicate entities: switch.ventilation, switch.toilet, switch.mirror, switch.sill, switch.spots_bath, switch.downstairs, switch.walk, switch.accent_bed, switch.vinyl, switch.upstairs, switch.accent_living\n"
     ]
    }
   ],
   "source": [
    "corr = statefulItemsets.corr()\n",
    "dupeList = []\n",
    "for row in corr:\n",
    "    for col in corr:\n",
    "        dupeEntity = []\n",
    "        if corr.loc[row,col] == 1 and row != col:\n",
    "            dupeEntity.append(row)\n",
    "            dupeEntity.append(col)\n",
    "            dupeEntitySorted = sorted(dupeEntity)\n",
    "            for dupeEntity in dupeEntitySorted:\n",
    "                if 'switch.' in dupeEntity and dupeEntity not in dupeList:\n",
    "                    dupeList.append(dupeEntity)\n",
    "df = df[~df['entity_id'].isin(dupeList)].reset_index(drop=True)\n",
    "test = test[~test['entity_id'].isin(dupeList)].reset_index(drop=True)\n",
    "statefulItemsets.drop(dupeList, axis=1, inplace=True)\n",
    "duplicatesFormat = ', '.join(dupeList)\n",
    "print(f'Deleted duplicate entities: {duplicatesFormat}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating bins: 100%|█████████▉| 29579/29581 [00:00<00:00, 54053.12it/s]\n"
     ]
    }
   ],
   "source": [
    "binLists = []\n",
    "iteration = 0\n",
    "for bin in tqdm(bins, desc=\"Generating bins\"):\n",
    "    startStop = []\n",
    "    startStop.append(bins[iteration])\n",
    "    startStop.append(bins[iteration + 1])\n",
    "    binLists.append(startStop)\n",
    "    iteration += 1\n",
    "    if iteration == len(bins) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id_state'].str.contains(\"-on\")]\n",
    "test = test[test['id_state'].str.contains(\"-on\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1274 itemsets in 13.527076244354248 seconds!\n"
     ]
    }
   ],
   "source": [
    "#Fill all bins with state changes in that timeslot\n",
    "startTime = time.time()\n",
    "timeslotsItemsets = []\n",
    "sunUp = False\n",
    "for binList in binLists:\n",
    "     current = df[(df.timestamp >= binList[0]) & (df.timestamp <= binList[0])]['id_state']\n",
    "     if len(current) > 0:\n",
    "          lastIteration = current\n",
    "          timeslotsItemsets.append(list(current))\n",
    "          if 'sun.sun-below_horizon' in list(current):\n",
    "               sunUp = False\n",
    "          elif 'sun.sun-above_horizon' in list(current):\n",
    "               sunUp = True\n",
    "          if sunUp == False:\n",
    "               timeslotsItemsets[-1].append('sun_below')\n",
    "          else:\n",
    "               timeslotsItemsets[-1].append('sun_above')\n",
    "\n",
    "for entityList in timeslotsItemsets:\n",
    "     if 'sun.sun-above_horizon' in entityList:\n",
    "          timeslotsItemsets.remove(entityList)\n",
    "     if 'sun.sun-below_horizon' in entityList:\n",
    "          timeslotsItemsets.remove(entityList)\n",
    "endTime = time.time()\n",
    "runningTime = endTime - startTime\n",
    "print(f'Generated {len(timeslotsItemsets)} itemsets in {runningTime} seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 171 itemsets in 0.8795249462127686 seconds!\n"
     ]
    }
   ],
   "source": [
    "def sessionGenerator(data):\n",
    "    startTime = time.time()\n",
    "    debug = False\n",
    "    #Initialize session itemsets list\n",
    "    sessionItemsets = []\n",
    "    #Initialize active section tracker variable\n",
    "    session = None\n",
    "    #Set initial sun value\n",
    "    sunUp = False\n",
    "    #Loop over all state changes in the dataframe\n",
    "    for stateChange in range(len(data)):\n",
    "        #Check if current state change is a sensor so a new session can be started if yes\n",
    "        if 'binary_sensor.' in data.iloc[stateChange]['id_state'] or 'switch.' in data.iloc[stateChange]['id_state']:\n",
    "            if session != None and len(session) > 1:\n",
    "                if sunUp == True:\n",
    "                    session.append('sun_above')\n",
    "                elif sunUp == False:\n",
    "                    session.append('sun_below')\n",
    "                sessionItemsets.append(session)\n",
    "            #Record start time of session\n",
    "            sessionStartTime = data.iloc[stateChange]['last_changed']\n",
    "            #Set session to current iteration\n",
    "            session = [data.iloc[stateChange]['id_state']]\n",
    "        #If not sensor, but a session is running, add to session if within interval\n",
    "        elif session != None and data.iloc[stateChange]['last_changed'] - sessionStartTime < pd.Timedelta(interval, \"s\"):\n",
    "            session.append(data.iloc[stateChange]['id_state'])\n",
    "        #If sun variable, change state of sun\n",
    "        elif 'sun.sun-below_horizon' in data.iloc[stateChange]['id_state']:\n",
    "            sunUp = False\n",
    "        elif 'sun.sun-above_horizon' in data.iloc[stateChange]['id_state']:\n",
    "            sunUp = True\n",
    "        #If not sensor, session is running but outside of interval add the sun state and stop the session\n",
    "        elif session != None and data.iloc[stateChange]['last_changed'] - sessionStartTime > pd.Timedelta(interval, \"s\"):\n",
    "            if len(session) > 1:\n",
    "                if sunUp == True:\n",
    "                    session.append('sun_above')\n",
    "                elif sunUp == False:\n",
    "                    session.append('sun_below')\n",
    "                sessionItemsets.append(session)\n",
    "                if debug == True:\n",
    "                    print(f'SESSION FOUND FROM {sessionStartTime} TO {sessionStartTime + pd.Timedelta(interval, \"s\")}')\n",
    "                    print(f'FOUND TOTAL OF {len(session) -1} ACTUATORS')\n",
    "                    print(session)\n",
    "                    time.sleep(4)\n",
    "                session = None\n",
    "        endTime = time.time()\n",
    "    runningTime = endTime - startTime\n",
    "    print(f'Generated {len(sessionItemsets)} itemsets in {runningTime} seconds!')\n",
    "    return sessionItemsets\n",
    "sessionItemsets = sessionGenerator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_encoder(data):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(data).transform(data)\n",
    "    return pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslotsEncoded = transaction_encoder(timeslotsItemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionsEncoded = transaction_encoder(sessionItemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "statefulEncoded = statefulItemsets.loc[:, ~statefulItemsets.columns.isin(['timeslot', 'dow'])].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAutomations(rules, metric, threshold):\n",
    "    automations = {\n",
    "    }\n",
    "    for antecedent in rules[rules[metric] > threshold]['antecedents'].unique():\n",
    "        consequentsList = []\n",
    "        for consequents in rules[rules['antecedents'] == antecedent]['consequents']:\n",
    "            for consequent in consequents.split(', '):\n",
    "                if consequent not in consequentsList:\n",
    "                    consequentsList.append(consequent)\n",
    "        antecedent = str(sorted(antecedent.split(', ')))\n",
    "        automations[antecedent] = sorted(consequentsList)\n",
    "    return automations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDict = {\n",
    "\"['binary_sensor.walk_motion_detection-on', 'sun_below']\": ['light.walk-on'],\n",
    "\"['binary_sensor.downstairs_hall_motion_detection-on']\": ['light.downstairs-on'],\n",
    "\"['binary_sensor.door_bath_motion_detection-on']\": ['light.sill-on','light.mirror-on','light.spots_bath-on'], \n",
    "\"['binary_sensor.walk_motion_detection-on']\": ['light.toilet-on'],\n",
    "\"['binary_sensor.door_living_motion_detection-on']\": ['light.kitchen-on', 'light.cupboard-on']\n",
    "\n",
    "}\n",
    "maxLength = 9000000\n",
    "def hyperDrive(data, freqLow, freqHigh, freqStep, antecedents_include, antecedents_exclude, consequents_exclude, ruleMetric = 'confidence', pruneMetric = 'lift', antecedent_len=0, verboseF = False):\n",
    "    startTime = time.time()\n",
    "    truthTable = pd.DataFrame(columns=df['entity_id'].unique())\n",
    "    results = []\n",
    "    freqLength = (freqHigh - freqLow)/freqStep\n",
    "    step = 0\n",
    "    initial = True\n",
    "    for minimalFrequency in np.arange(freqLow, freqHigh , freqStep):\n",
    "        if initial == True:\n",
    "            initial = False\n",
    "        else:\n",
    "            step += 1\n",
    "        frequentMine = fpgrowth(data, min_support=minimalFrequency, use_colnames=True)\n",
    "        if len(frequentMine) > 0 and len(frequentMine) < maxLength:\n",
    "            metrLow = 0\n",
    "            metrHigh = 1\n",
    "            metrStep = .1\n",
    "            metrLength = (metrHigh - metrLow)/metrStep\n",
    "            stepMet = 0\n",
    "            for metricThreshold in np.arange(metrLow,metrHigh,metrStep):\n",
    "                #print(f'-------METRIC THRESHOLD: {metricThreshold}')\n",
    "                print(f'Progress: {step}/{freqLength}, Metric: {stepMet}/{metrLength}', end='\\r')\n",
    "                stepMet += 1\n",
    "                rules = association_rules(frequentMine,  metric=ruleMetric, min_threshold=metricThreshold)\n",
    "                rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "                rules[\"consequents_len\"] = rules[\"consequents\"].apply(lambda x: len(x))\n",
    "                rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: ', '.join(list(x))).astype(\"unicode\")\n",
    "                rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: ', '.join(list(x))).astype(\"unicode\")\n",
    "                if antecedent_len > 0:\n",
    "                    filteredRules = rules[(rules['antecedents'].str.contains('|'.join(antecedents_include))) & ~(rules['antecedents'].str.contains('|'.join(antecedents_exclude))) & ~(rules['consequents'].str.contains('|'.join(consequents_exclude))) & (rules['antecedent_len'] == antecedent_len)]\n",
    "                else:\n",
    "                    filteredRules = rules[(rules['antecedents'].str.contains('|'.join(antecedents_include))) & ~(rules['antecedents'].str.contains('|'.join(antecedents_exclude))) & ~(rules['consequents'].str.contains('|'.join(consequents_exclude)))]\n",
    "                if pruneMetric == 'confidence':\n",
    "                    pruneThreshLow = 0\n",
    "                    pruneThreshHigh = 1\n",
    "                    pruneThreshStep = 0.2\n",
    "                elif pruneMetric == 'lift' or pruneMetric == 'conviction':\n",
    "                    pruneThreshLow = 0\n",
    "                    pruneThreshHigh = 25\n",
    "                    pruneThreshStep = 0.5\n",
    "                for pruneThreshold in np.arange(pruneThreshLow,pruneThreshHigh,pruneThreshStep):\n",
    "                    automations = generateAutomations(filteredRules, pruneMetric, pruneThreshold)\n",
    "                    if verboseF == True and len(automations) > 0:\n",
    "                        print(automations)\n",
    "                    \n",
    "                    for value in validationDict.values():\n",
    "                        value.sort()\n",
    "                    tp = 0\n",
    "                    fp = 0\n",
    "                    for automation in automations.items():\n",
    "                        for entityState in automation:\n",
    "                            truthTable[entityState] = 1\n",
    "                        if automation in validationDict.items():\n",
    "                            tp += 1\n",
    "                        else:\n",
    "                            fp += 1\n",
    "                    if tp > 0:\n",
    "                        fn = len(validationDict) - tp\n",
    "                        recall = (tp)/(tp+fn)\n",
    "                        precision = (tp)/(tp+fp)\n",
    "                        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "                        result = [minimalFrequency, len(frequentMine), metricThreshold, len(rules), pruneThreshold, precision, recall, f1, tp, fp, fn, len(automations), {str(automations.keys())}, {str(automations.values())}]\n",
    "                        results.append(result)\n",
    "\n",
    "    overview = pd.DataFrame.from_records(results, columns=['minimal_frequency', 'itemsets_mined', f'{ruleMetric}_threshold', 'rules_mined', f'{pruneMetric}_prune_threshold', 'precision', 'recall', 'f1' , 'tp', 'fp', 'fn', 'rule_length', 'antecedents', 'consequents'])\n",
    "    endTime = time.time()\n",
    "    runningTime = round(endTime - startTime, 2)\n",
    "    if len(overview) > 0:\n",
    "        bestAutomation = overview.sort_values(['recall', 'precision', 'confidence_threshold', 'lift_prune_threshold'],ascending = [False, False, False, False]).iloc[0]\n",
    "        bestItemsetAmount = bestAutomation['itemsets_mined']\n",
    "        bestRuleAmount = bestAutomation['rules_mined']\n",
    "        bestPruneAmount = bestAutomation['rule_length']\n",
    "        bestPrecision = bestAutomation['precision']\n",
    "        bestRecall = bestAutomation['recall']\n",
    "        bestf1 = bestAutomation['f1']\n",
    "        bestMinfreq = bestAutomation['minimal_frequency']\n",
    "        bestMetricThresh = bestAutomation[f'{ruleMetric}_threshold']\n",
    "        bestPruneThresh = bestAutomation[f'{pruneMetric}_prune_threshold']\n",
    "        print('--------------------PERFORMANCE-----------------------')\n",
    "        print(f'Completed in {runningTime} seconds')\n",
    "        print('--------------------COUNTS-----------------------')\n",
    "        print(f'Total itemsets: {len(data)}')\n",
    "        print(f'Frequent itemsets: {bestItemsetAmount}')\n",
    "        print(f'Rules: {bestRuleAmount}')\n",
    "        print(f'Rules after pruning: {bestPruneAmount}')\n",
    "        print('--------------------METRICS-----------------------')\n",
    "        print(f'Min sup frequency: {bestMinfreq}')\n",
    "        print(f'{ruleMetric} threshold:{bestMetricThresh}')\n",
    "        print(f'{pruneMetric} prune threshold:{bestPruneThresh}')\n",
    "        print(f'TP: {bestAutomation[\"tp\"]}, FP: {bestAutomation[\"fp\"]}, FN: {bestAutomation[\"fn\"]}')\n",
    "        print(f'Precision: {bestPrecision}')\n",
    "        print(f'Recall:{bestRecall}')\n",
    "        print(f'F1:{bestf1}')\n",
    "        antlist = str(bestAutomation['antecedents']).split(']\", ')\n",
    "        conlist = str(bestAutomation['consequents']).split('], ')\n",
    "        display(pd.DataFrame({'Antecedents': antlist, 'Consequents': conlist}))\n",
    "    else: print('No rules found.')\n",
    "    return overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------PERFORMANCE-----------------------\n",
      "Completed in 8.27 seconds\n",
      "--------------------COUNTS-----------------------\n",
      "Total itemsets: 1357\n",
      "Frequent itemsets: 109\n",
      "Rules: 628\n",
      "Rules after pruning: 8\n",
      "--------------------METRICS-----------------------\n",
      "Min sup frequency: 0.011\n",
      "confidence threshold:0.1\n",
      "lift prune threshold:1.5\n",
      "TP: 3, FP: 5, FN: 2\n",
      "Precision: 0.375\n",
      "Recall:0.6\n",
      "F1:0.4615384615384615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antecedents</th>\n",
       "      <th>Consequents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'dict_keys([\"[\\'binary_sensor.walk_motion_detection-on\\'</td>\n",
       "      <td>{\"dict_values([['light.toilet-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[\\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'</td>\n",
       "      <td>['light.toilet-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'sun_below\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'binary_sensor.walk_motion_detection-on\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"[\\'binary_sensor.downstairs_hall_motion_detection-on\\'</td>\n",
       "      <td>['light.downstairs-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"[\\'binary_sensor.downstairs_hall_motion_detection-on\\', \\'sun_below\\']\"])'}</td>\n",
       "      <td>['light.downstairs-on']])\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    Antecedents  \\\n",
       "0                                                     {'dict_keys([\"[\\'binary_sensor.walk_motion_detection-on\\'   \n",
       "1                                                   \"[\\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'   \n",
       "2                                                             \"[\\'binary_sensor.door_bath_motion_detection-on\\'   \n",
       "3                                              \"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'sun_below\\'   \n",
       "4                 \"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'binary_sensor.walk_motion_detection-on\\'   \n",
       "5  \"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'   \n",
       "6                                                       \"[\\'binary_sensor.downstairs_hall_motion_detection-on\\'   \n",
       "7                                  \"[\\'binary_sensor.downstairs_hall_motion_detection-on\\', \\'sun_below\\']\"])'}   \n",
       "\n",
       "                                                  Consequents  \n",
       "0                           {\"dict_values([['light.toilet-on'  \n",
       "1                                          ['light.toilet-on'  \n",
       "2  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "3  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "4  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "5  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "6                                      ['light.downstairs-on'  \n",
       "7                                 ['light.downstairs-on']])\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timeslotAutomations = hyperDrive(timeslotsEncoded, ruleMetric = 'confidence', pruneMetric = 'lift', freqLow=0.001 ,freqHigh = 0.1, freqStep = 0.01, antecedents_include = ['binary_sensor'], antecedents_exclude = ['light'], consequents_exclude = ['sun', 'binary_sensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------PERFORMANCE-----------------------\n",
      "Completed in 72.72 seconds\n",
      "--------------------COUNTS-----------------------\n",
      "Total itemsets: 184\n",
      "Frequent itemsets: 337\n",
      "Rules: 5979\n",
      "Rules after pruning: 6\n",
      "--------------------METRICS-----------------------\n",
      "Min sup frequency: 0.011\n",
      "confidence threshold:0.7000000000000001\n",
      "lift prune threshold:1.5\n",
      "TP: 3, FP: 3, FN: 2\n",
      "Precision: 0.5\n",
      "Recall:0.6\n",
      "F1:0.5454545454545454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antecedents</th>\n",
       "      <th>Consequents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'dict_keys([\"[\\'binary_sensor.walk_motion_detection-on\\'</td>\n",
       "      <td>{\"dict_values([['light.toilet-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[\\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'</td>\n",
       "      <td>['light.toilet-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'sun_below\\'</td>\n",
       "      <td>['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[\\'binary_sensor.downstairs_hall_motion_detection-on\\'</td>\n",
       "      <td>['light.downstairs-on'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"[\\'binary_sensor.downstairs_hall_motion_detection-on\\', \\'sun_below\\']\"])'}</td>\n",
       "      <td>['light.downstairs-on']])\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Antecedents  \\\n",
       "0                     {'dict_keys([\"[\\'binary_sensor.walk_motion_detection-on\\'   \n",
       "1                   \"[\\'binary_sensor.walk_motion_detection-on\\', \\'sun_below\\'   \n",
       "2                             \"[\\'binary_sensor.door_bath_motion_detection-on\\'   \n",
       "3              \"[\\'binary_sensor.door_bath_motion_detection-on\\', \\'sun_below\\'   \n",
       "4                       \"[\\'binary_sensor.downstairs_hall_motion_detection-on\\'   \n",
       "5  \"[\\'binary_sensor.downstairs_hall_motion_detection-on\\', \\'sun_below\\']\"])'}   \n",
       "\n",
       "                                                  Consequents  \n",
       "0                           {\"dict_values([['light.toilet-on'  \n",
       "1                                          ['light.toilet-on'  \n",
       "2  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "3  ['light.mirror-on', 'light.sill-on', 'light.spots_bath-on'  \n",
       "4                                      ['light.downstairs-on'  \n",
       "5                                 ['light.downstairs-on']])\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionsAutomations = hyperDrive(sessionsEncoded, ruleMetric = 'confidence', pruneMetric = 'lift', freqLow=0.001 ,freqHigh = 0.1, freqStep = 0.001, antecedents_include = ['binary_sensor'], antecedents_exclude = ['light'], consequents_exclude = ['sun', 'binary_sensor'])\n",
    "#sessionsAutomations.sort_values(['discovery_rate', 'precision'],ascending = [False, False]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rules found..00000000000001, Metric: 9/10.0\n"
     ]
    }
   ],
   "source": [
    "statefulAutomations = hyperDrive(statefulEncoded, ruleMetric = 'confidence', pruneMetric = 'lift', freqLow=0.01 ,freqHigh = 0.1, freqStep = 0.001, antecedents_include = ['binary_sensor'], antecedents_exclude = ['light'], consequents_exclude = ['sun', 'binary_sensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 140 itemsets in 0.8527510166168213 seconds!\n"
     ]
    }
   ],
   "source": [
    "sessionItemsets_test = sessionGenerator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------AUTOMATION 1-------\n",
      "['binary_sensor.door_bath_motion_detection-on']\n",
      "['light.mirror-on', 'light.sill-on', 'light.spots_bath-on']\n",
      "-------AUTOMATION 2-------\n",
      "['binary_sensor.door_bath_motion_detection-on', 'sun_below']\n",
      "['light.mirror-on', 'light.sill-on', 'light.spots_bath-on']\n",
      "-------AUTOMATION 3-------\n",
      "['binary_sensor.walk_motion_detection-on']\n",
      "['light.toilet-on']\n",
      "-------AUTOMATION 4-------\n",
      "['binary_sensor.walk_motion_detection-on', 'sun_below']\n",
      "['light.toilet-on']\n",
      "-------AUTOMATION 5-------\n",
      "['binary_sensor.door_living_motion_detection-on', 'media_player.tv-on']\n",
      "['media_player.receiver-on']\n",
      "-------AUTOMATION 6-------\n",
      "['binary_sensor.door_living_motion_detection-on', 'media_player.tv-on', 'sun_below']\n",
      "['media_player.receiver-on']\n"
     ]
    }
   ],
   "source": [
    "#VALIDATION\n",
    "sessionItemsets_testEncoded = transaction_encoder(sessionItemsets_test)\n",
    "frequentSessionsTest = fpgrowth(sessionItemsets_testEncoded , min_support=0.005, use_colnames=True)\n",
    "sessionsRuleTest = association_rules(frequentSessionsTest, metric=\"confidence\", min_threshold=0.7)\n",
    "sessionsRuleTest[\"consequents\"] = sessionsRuleTest[\"consequents\"].apply(lambda x: ', '.join(list(x))).astype(\"unicode\")\n",
    "sessionsRuleTest[\"antecedents\"] = sessionsRuleTest[\"antecedents\"].apply(lambda x: ', '.join(list(x))).astype(\"unicode\")\n",
    "\n",
    "antecedents_include = ['binary_sensor']\n",
    "antecedents_exclude = ['light']\n",
    "consequents_exclude = ['sun', 'binary_sensor']\n",
    "final = sessionsRuleTest[(sessionsRuleTest['antecedents'].str.contains('|'.join(antecedents_include))) & ~(sessionsRuleTest['antecedents'].str.contains('|'.join(antecedents_exclude))) & ~(sessionsRuleTest['consequents'].str.contains('|'.join(consequents_exclude)))]\n",
    "\n",
    "automations = generateAutomations(final, 'lift', 1.5)\n",
    "counter = 1\n",
    "for automation in automations:\n",
    "    print(f'-------AUTOMATION {counter}-------')\n",
    "    counter += 1\n",
    "    print(automation)\n",
    "    print(automations[automation])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
